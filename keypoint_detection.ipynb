{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoint detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from the blog post at https://fairyonice.github.io/achieving-top-23-in-kaggles-facial-keypoints-detection-with-keras-tensorflow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --user --upgrade numpy pandas scikit-learn matplotlib\n",
    "!pip install --user --upgrade tensorflow\n",
    "!pip install --user --upgrade keras\n",
    "# https://stackoverflow.com/questions/49887968/what-does-symbol-not-found-clock-gettime-mean-when-calling-a-python-2-7-scri\n",
    "!pip install --force-reinstall Pillow==5.0.0\n",
    "!pip install --user --upgrade imgaug\n",
    "!pip install --upgrade opencv-python==3.3.0.10\n",
    "# https://stackoverflow.com/questions/48717726/python3-opencv-install-error-symbol-not-found-clock-gettime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "print \"cv2 version\", cv2.__version__\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls data/facial-keypoints-detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path=os.path.join(\"data\", \"facial-keypoints-detection\")\n",
    "FTRAIN = os.path.join(path,\"training.csv\")\n",
    "FTEST = os.path.join(path, \"test.csv\")\n",
    "FIdLookup = os.path.join(path, \"IdLookupTable.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Image loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sample(X,y,axs):\n",
    "    '''\n",
    "    kaggle picture is 96 by 96\n",
    "    y is rescaled to range between -1 and 1\n",
    "    '''\n",
    "    \n",
    "    axs.imshow(X.reshape(96,96),cmap=\"gray\")\n",
    "    axs.scatter(48*y[0::2]+ 48,48*y[1::2]+ 48)\n",
    "    \n",
    "def load(test=False, cols=None):\n",
    "    \"\"\"\n",
    "    load test/train data\n",
    "    cols : a list containing landmark label names.\n",
    "           If this is specified, only the subset of the landmark labels are \n",
    "           extracted. for example, cols could be:\n",
    "           \n",
    "          [left_eye_center_x, left_eye_center_y]\n",
    "            \n",
    "    return: \n",
    "    X: 2-d numpy array (Nsample, Ncol*Nrow)\n",
    "    y: 2-d numpy array (Nsample, Nlandmarks*2) \n",
    "       In total there are 15 landmarks. \n",
    "       As x and y coordinates are recorded, u.shape = (Nsample,30)\n",
    "       \n",
    "    \"\"\"\n",
    "\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname)) \n",
    "\n",
    "    \n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    if cols:  \n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    myprint = df.count()\n",
    "    myprint = myprint.reset_index()\n",
    "    print(myprint)  \n",
    "    ## row with at least one NA columns are removed!\n",
    "    df = df.dropna()  \n",
    "    \n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.  # changes valeus between 0 and 1\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:  # labels only exists for the training data\n",
    "        ## standardization of the response\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # y values are between [-1,1]\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def load2d(test=False,cols=None):\n",
    "\n",
    "    re = load(test, cols)\n",
    "    \n",
    "    X = re[0].reshape(-1,96,96,1)\n",
    "    y = re[1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def plot_loss(hist,name,plt,RMSE_TF=False):\n",
    "    '''\n",
    "    RMSE_TF: if True, then RMSE is plotted with original scale \n",
    "    '''\n",
    "    loss = hist['loss']\n",
    "    val_loss = hist['val_loss']\n",
    "    if RMSE_TF:\n",
    "        loss = np.sqrt(np.array(loss))*48 \n",
    "        val_loss = np.sqrt(np.array(val_loss))*48 \n",
    "        \n",
    "    plt.plot(loss,\"--\",linewidth=3,label=\"train:\"+name)\n",
    "    plt.plot(val_loss,linewidth=3,label=\"val:\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"X.shape == {}; X.min == {:.3f}; X.max == {:.3f}\".format(X.shape, X.min(), X.max()))\n",
    "print(\"y.shape == {}; y.min == {:.3f}; y.max == {:.3f}\".format(y.shape, y.min(), y.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As visible we have 2140 entries for both X and labels, where 96x96 sized images are flattened to a 9216-long array, and similarly 15 keypoints are placed contiguously in a 30-element array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2, y2 = load2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"X2.shape == {}; X2.min == {:.3f}; X2.max == {:.3f}\".format(X2.shape, X2.min(), X2.max()))\n",
    "print(\"y2.shape == {}; y2.min == {:.3f}; y2.max == {:.3f}\".format(y2.shape, y2.min(), y2.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting on unprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "fig.subplots_adjust(hspace=0.13,wspace=0.0001,\n",
    "                    left=0,right=1,bottom=0, top=1)\n",
    "Npicture = 3\n",
    "count = 1\n",
    "for irow in range(Npicture):\n",
    "    ipic = np.random.choice(X2.shape[0])\n",
    "    ax = fig.add_subplot(Npicture/3 , 3, count,xticks=[],yticks=[])\n",
    "    plot_sample(X2[ipic],y2[ipic],ax)\n",
    "    ax.set_title(\"picture \"+ str(ipic))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = X2.shape[1]\n",
    "h = X2.shape[2]\n",
    "c = X2.shape[3]\n",
    "print w, h, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ia.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to apply keypoints to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keypoints_1d_to_2d(keypoints):\n",
    "    return [(keypoints[2*i], keypoints[2*i+1]) for i in range(len(keypoints)/2) ]\n",
    "\n",
    "def add_keypoints_on_image(img, keypoints):\n",
    "    # reshape the keypoints to pairs\n",
    "    return KeypointsOnImage([\n",
    "           Keypoint(x=x, y=y) for (x, y) in keypoints_1d_to_2d(keypoints) \n",
    "        ], shape=img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the augmentation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Multiply((1.2, 1.5)), # change brightness, doesn't affect keypoints\n",
    "    iaa.Affine(\n",
    "        rotate=10,\n",
    "        scale=(0.5, 0.7)\n",
    "    ) # rotate by exactly 10deg and scale to 50-70%, affects keypoints\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on an example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = ia.quokka(size=(256, 256))\n",
    "keypoints=[65, 100, 75, 200, 100, 100, 200, 80]\n",
    "koi = add_keypoints_on_image(image, keypoints)\n",
    "koi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Augment keypoints and images.\n",
    "image_aug, kps_aug = seq(image=image, keypoints=koi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# image with keypoints before/after augmentation (shown below)\n",
    "image_before = koi.draw_on_image(image, size=7)\n",
    "image_after = kps_aug.draw_on_image(image_aug, size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the image for the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input image is already in range [0, 1], as well as the keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"X2.shape == {}; X2.min == {:.3f}; X2.max == {:.3f}\".format(X2.shape, X2.min(), X2.max()))\n",
    "print(\"y2.shape == {}; y2.min == {:.3f}; y2.max == {:.3f}\".format(y2.shape, y2.min(), y2.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_image_as_greyscale(path):\n",
    "    return cv2.imread(path, 0)\n",
    "\n",
    "def plot_image(img):\n",
    "    # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_image_display/py_image_display.html#using-matplotlib\n",
    "    plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_image = load_image_as_greyscale(\"data/VOCdevkit/VOC2012/JPEGImages/2007_000027.jpg\")\n",
    "print(test_image.shape)\n",
    "plot_image(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rescale the image in [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(test_image.shape)\n",
    "print(test_image.min(), test_image.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example at https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "pixels = asarray(test_image)\n",
    "# confirm pixel range is 0-255\n",
    "print('Data Type: %s' % pixels.dtype)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# normalize to the range 0-1\n",
    "pixels /= 255.0\n",
    "# confirm the normalization\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "print(pixels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pack this into a reusable function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_image(img):\n",
    "    pixels = asarray(img)\n",
    "    pixels = img.astype('float32')\n",
    "    if pixels.max() > 1.0:\n",
    "        pixels /= 255.0\n",
    "    return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X2[0].shape\n",
    "converted_img = convert_image(X2[0])\n",
    "plt.imshow(converted_img.reshape(96,96),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the keypoints for the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the input image, we also expect the labels (keypoint positions) to be in the interval [0,1].\n",
    "To recap, we previously had the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "koi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kps_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kps_aug.keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kps_aug.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can easily normalize these values based on the image shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_keypoints(kps):\n",
    "    result = []\n",
    "    for k in kps.keypoints:\n",
    "        result.append( k.x / float(kps.shape[0]) ) # x / x_max\n",
    "        result.append( k.y / float(kps.shape[1]) ) # y / y_max\n",
    "    return np.array(result)\n",
    "\n",
    "def denormalize_keypoints(kps, img_width, img_height):\n",
    "    kps = []\n",
    "    for i, k in enumerate(kps):\n",
    "        kps.append(k * ( img_width if i % 2 == 0 else img_height))\n",
    "    return kps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize_keypoints(kps_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def SimpleCNN(input_shape=(96,96,1), withDropout=False):\n",
    "    '''\n",
    "    WithDropout: If True, then dropout regularlization is added.\n",
    "    This feature is experimented later.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape = input_shape))\n",
    "    model.add(Activation('relu')) ## 96 - 3 + 2\n",
    "    model.add(MaxPooling2D(pool_size = (2,2))) ## 96 - (3-1)*2\n",
    "    if withDropout:\n",
    "        model.add(Dropout(0.1))\n",
    "        \n",
    "    model.add(Conv2D(64, (2,2)))\n",
    "    model.add(Activation('relu')) ## \n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    if withDropout:\n",
    "        model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv2D(128, (2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    if withDropout:\n",
    "        model.add(Dropout(0.1))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation('relu'))\n",
    "    if withDropout:\n",
    "        model.add(Dropout(0.1))\n",
    "        \n",
    "    model.add(Dense(500))\n",
    "    model.add(Activation('relu'))\n",
    "    if withDropout:\n",
    "        model.add(Dropout(0.1))\n",
    "        \n",
    "    model.add(Dense(30))\n",
    "    sgd = SGD(lr=0.01,momentum = 0.9,nesterov=True)\n",
    "    model.compile(loss=\"mean_squared_error\",optimizer=sgd)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an image generator for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example taken from https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input(path):\n",
    "    return load_image_as_greyscale(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output(path, label_file):\n",
    "    #get the file id\n",
    "    img_id = path.split('/')[-1].split('.')[0]\n",
    "    img_id = np.int64(img_id)\n",
    "    return label_file.loc[img_id].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_generator(files, label_file, batch_size = 64):\n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_paths = np.random.choice(a = files, size = batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = [] \n",
    "          \n",
    "        # Read in each input, perform preprocessing and get labels         \n",
    "        for input_path in batch_paths:\n",
    "            in_image = get_input(input_path)\n",
    "            label = get_output(input_path, label_file=label_file )\n",
    "            \n",
    "            in_image = preprocess_input(image=in_image)\n",
    "            batch_input += [ in_image ]\n",
    "            batch_output += [ label ]\n",
    "            \n",
    "        # Return a tuple of (input,output) to feed the network \n",
    "        batch_x = np.array( batch_input )\n",
    "        batch_y = np.array( batch_output )\n",
    "        \n",
    "        yield( batch_x, batch_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an image generator over 1 image and 1 label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.choice(a = X2.shape[0], size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_input(image, keypoints, target_width, target_height, channels):\n",
    "    # convert from 1-D to 2-D image\n",
    "    #image = image.reshape(-1, target_width, target_height,1)\n",
    "    #image = image.reshape(target_width, target_height, channels)\n",
    "    # add keypoints on image\n",
    "    koi = add_keypoints_on_image(image, keypoints)\n",
    "    # augment image and keypoints\n",
    "    #print image.shape\n",
    "    image_aug, kps_aug = seq(image=image, keypoints=koi)\n",
    "    #print \"augmented: \", image_aug.shape, kps_aug.shape\n",
    "    # rescale image and keypoints in [0, 1]\n",
    "    image_aug = convert_image(image_aug)\n",
    "    #print \"converted:\", image_aug.shape\n",
    "    kps = normalize_keypoints(kps_aug)\n",
    "    return image_aug, kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(preprocess_input(image, keypoints, 256, 256, 3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_input(image, keypoints, 256, 256, 3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def image_generator(images_file, labels_file, dimensions=2, batch_size = 64, target_width=None, target_height=None, channels=None):\n",
    "    if target_width is None or target_height is None:\n",
    "        target_width = target_height = int(math.sqrt(images_file.shape[1]))\n",
    "    while True:\n",
    "        dataset_size = len(images_file)\n",
    "        batch_indexes = np.random.choice(a = dataset_size, size = batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        # Read in each input, perform preprocessing and get labels         \n",
    "        for input_index in batch_indexes:\n",
    "            in_image = images_file[input_index]\n",
    "            label = labels_file[input_index]\n",
    "            #print \"in_image.shape\", in_image.shape, \"label.shape\", label.shape\n",
    "            #print \"target_width\", target_width, \"target_height\", target_height\n",
    "            # preprocess image\n",
    "            img_aug, kps = preprocess_input(in_image, label, target_width, target_height, channels)\n",
    "            #print \"preprocessed:\", img_aug.shape, kps.shape\n",
    "            if dimensions == 1:\n",
    "                if len(img_aug.shape) == 3 and img_aug.shape[2] != 1:\n",
    "                    img_aug = np.reshape(img_aug, (img_aug.shape[0] * img_aug.shape[1], img_aug.shape[2] ))\n",
    "                else:\n",
    "                    #img_aug = np.reshape(img_aug, (img_aug.shape[0] * img_aug.shape[1]))\n",
    "                    img_aug = img_aug.flatten()\n",
    "            \n",
    "            #print \"reshaped\", img_aug.shape\n",
    "            batch_input += [ img_aug ]\n",
    "            batch_output += [ kps ]\n",
    "            \n",
    "        # Return a tuple of (input,output) to feed the network \n",
    "        batch_x = np.array( batch_input )\n",
    "        batch_y = np.array( batch_output )\n",
    "        #print \"Batch: \", batch_x.shape, batch_y.shape\n",
    "        yield( batch_x, batch_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_input(X2[0], y2[0], 96, 96, 1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_generator(images_file, labels_file, dimensions=1, batch_size = 1, target_width=None, target_height=None, channels=None):\n",
    "    # Select files (paths/indices) for the batch\n",
    "    dataset_size = len(images_file)\n",
    "    batch_indexes = np.random.choice(a = dataset_size, size = batch_size)\n",
    "    batch_input = []\n",
    "    batch_output = [] \n",
    "          \n",
    "    # Read in each input, perform preprocessing and get labels         \n",
    "    for input_index in batch_indexes:\n",
    "        in_image = images_file[input_index]\n",
    "        label = labels_file[input_index]\n",
    "        #print \"in_image.shape\", in_image.shape, \"label.shape\", label.shape\n",
    "        #print \"target_width\", target_width, \"target_height\", target_height\n",
    "        # preprocess image\n",
    "        img_aug, kps = preprocess_input(in_image, label, target_width, target_height, channels)\n",
    "        #print \"preprocessed:\", img_aug.shape, kps.shape\n",
    "        if dimensions == 1:\n",
    "            if len(img_aug.shape) == 3 and img_aug.shape[2] != 1:\n",
    "                img_aug = np.reshape(img_aug, (img_aug.shape[0] * img_aug.shape[1], img_aug.shape[2] ))\n",
    "            else:\n",
    "                #img_aug = np.reshape(img_aug, (img_aug.shape[0] * img_aug.shape[1]))\n",
    "                img_aug = img_aug.flatten()\n",
    "            \n",
    "        #print \"reshaped\", img_aug.shape\n",
    "        batch_input += [ img_aug ]\n",
    "        batch_output += [ kps ]\n",
    "            \n",
    "        # Return a tuple of (input,output) to feed the network \n",
    "        batch_x = np.array( batch_input )\n",
    "        batch_y = np.array( batch_output )\n",
    "        #print \"Batch: \", batch_x.shape, batch_y.shape\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = test_generator(X2[0:4], y2[0:4], dimensions=1, batch_size=1, target_width=96, target_height=96, channels=1)\n",
    "print a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = test_generator(X2[0:4], y2[0:4], dimensions=2, batch_size=1, target_width=96, target_height=96, channels=1)\n",
    "print a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_3_channels(img, width, height):\n",
    "    tmp = np.reshape(img, (width, height))\n",
    "    return np.stack((tmp, tmp, tmp), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnn_model = SimpleCNN(input_shape=(96,96, 1))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the number of epochs and batch size\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "# train the network\n",
    "hist = cnn_model.fit_generator(\n",
    "    \n",
    "    image_generator(\n",
    "        X_train, y_train, dimensions=2,\n",
    "        batch_size=batch_size, target_width=96, target_height=96, channels=1\n",
    "    ),\n",
    "    validation_data=image_generator(\n",
    "        X_val, y_val, dimensions=2,\n",
    "        batch_size=batch_size, target_width=96, target_height=96, channels=1\n",
    "    ),\n",
    "    validation_steps=len(X_val) // batch_size,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_loss(hist.history,\"model 1\",plt)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"log loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_y_test = cnn_model.predict(X_val.reshape(428, 96, 96, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print predicted_y_test.min(), predicted_y_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "fig.subplots_adjust(hspace=0.13,wspace=0.0001,\n",
    "                    left=0,right=1,bottom=0, top=1)\n",
    "Npicture = 9\n",
    "count = 1\n",
    "for irow in range(Npicture):\n",
    "    ipic = np.random.choice(X_val.shape[0])\n",
    "    ax = fig.add_subplot(Npicture/3 , 3, count, xticks=[], yticks=[])        \n",
    "    # denormalize_keypoints(predicted_y_test[ipic], 96, 96)\n",
    "    plot_sample(X_val[ipic], predicted_y_test[ipic], ax)\n",
    "    ax.set_title(\"picture \"+ str(ipic))\n",
    "    count += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img-notebooks",
   "language": "python",
   "name": "img-notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
